# Dynamical Similarity Analysis Applied to LMs

The paper, [*Beyond Geometry: Comparing the Temporal Structure of Computation in Neural Circuits with Dynamical Similarity Analysis*](https://arxiv.org/abs/2306.10168) ([official implementation](https://github.com/mitchellostrow/DSA/), from which I built upon), introduces Dynamical Similarity Analysis (DSA), a method to compare two systems based on their dynamics rather than just their geometrical structure. The authors argue that for systems, such as recurrent neural networks (RNNs), the computation is embedded in the dynamics, and standard geometric similarity methods are insufficient. DSA leverages advances in dynamical systems theory and statistical shape analysis to embed nonlinear dynamics into a globally linear space using Koopman operators. It then applies an extended form of Procrustes Analysis to capture dynamical similarities between different systems. The method is tested on several neural network architectures, showing that it can distinguish between dynamically different systems even when their geometries are similar and vice versa.

Here, I extend the methods proposed in this paper by applying DSA to compare the dynamics of different language model embeddings.
